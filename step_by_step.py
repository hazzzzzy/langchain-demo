import datetime
import os
from typing import Annotated, TypedDict
from typing import Literal

from langchain_core.messages import BaseMessage, HumanMessage, SystemMessage
from langchain_deepseek import ChatDeepSeek
from langgraph.graph import StateGraph
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode

from config.logger_config import setup_logging
from config.prompt.step_by_step_prompt import AGENT_SYSTEM_PROMPT, AGENT_USER_PROMPT
from utils.agent_tools import agent_search_vector, query_mysql

os.environ["LANGCHAIN_PROJECT"] = "Text2SQL_Agent"
logger = setup_logging()


class AgentState(TypedDict):
    # add_messages æ˜¯ LangGraph çš„é»‘é­”æ³•ï¼š
    # å½“èŠ‚ç‚¹è¿”å›æ–°çš„ message æ—¶ï¼Œå®ƒä¸æ˜¯è¦†ç›–ï¼Œè€Œæ˜¯ appendï¼ˆè¿½åŠ ï¼‰åˆ°åˆ—è¡¨é‡Œ
    messages: Annotated[list[BaseMessage], add_messages]


# 1. åˆå§‹åŒ– LLM å¹¶ç»‘å®šå·¥å…·
# bind_tools è®© DeepSeek çŸ¥é“å®ƒæœ‰äº†â€œæŸ¥æ•°æ®åº“â€çš„èƒ½åŠ›
llm = ChatDeepSeek(model="deepseek-chat", temperature=0.6)
tools = [query_mysql, agent_search_vector]
llm_with_tools = llm.bind_tools(tools)


# 2. å®šä¹‰ã€æ€è€ƒèŠ‚ç‚¹ã€‘ (Brain)
def agent_node(state: AgentState):
    # print("[AI æ€è€ƒä¸­]...")
    messages = state["messages"]
    # LLM ä¼šçœ‹ä¹‹å‰çš„å¯¹è¯å†å²ï¼Œå†³å®šæ˜¯ç›´æ¥å›ç­”ï¼Œè¿˜æ˜¯è°ƒç”¨å·¥å…·
    response = llm_with_tools.invoke(messages)
    return {"messages": [response]}


# def summary_node(state: AgentState):
#     messages = state["messages"]
#     # print(messages)
#
#     question = messages[1].content
#     answer = messages[-1].content
#     # logger.info(question,)
#     # logger.info(answer)
#
#     prompt = ChatPromptTemplate.from_messages([
#         ("system", SUMMARY_AGENT_SYSTEM_PROMPT),
#         ("user", SUMMARY_AGENT_USER_PROMPT)
#     ])
#
#     chain = prompt | llm | StrOutputParser()
#     summary_context = chain.invoke({
#         'question': question,
#         'answer': answer,
#     })
#     logger.info(summary_context)
#     return {"messages": [AIMessage(content=summary_context)]}


# 3. å®šä¹‰ã€å·¥å…·èŠ‚ç‚¹ã€‘ (Action)
# ToolNode æ˜¯ LangGraph è‡ªå¸¦çš„ï¼Œå®ƒä¼šè‡ªåŠ¨è¯†åˆ« LLM è¿”å›çš„ tool_calls å¹¶æ‰§è¡Œ


def should_continue(state: AgentState) -> Literal["tools", "__end__"]:
    messages = state["messages"]
    last_message = messages[-1]

    # å¦‚æœ LLM çš„å›å¤é‡ŒåŒ…å« tool_callsï¼Œè¯´æ˜å®ƒæƒ³æŸ¥åº“ -> è½¬å»å·¥å…·èŠ‚ç‚¹
    if last_message.tool_calls:
        return "tools"
    # print(messages)
    # å¦åˆ™è¯´æ˜å®ƒè§‰å¾—ä¿¡æ¯å¤Ÿäº†ï¼Œå·²ç»ç”Ÿæˆäº†æœ€ç»ˆæ–‡æœ¬ -> ç»“æŸ
    return "__end__"


def build_graph():
    workflow = StateGraph(AgentState)

    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("ReAct", agent_node)

    tool_node = ToolNode(tools)
    workflow.add_node("tools", tool_node)
    # workflow.add_node("summary", summary_node)

    # è®¾ç½®å…¥å£
    workflow.set_entry_point("ReAct")

    # æ·»åŠ æ¡ä»¶è¾¹ï¼šAI æ€è€ƒå®Œåï¼Œå†³å®šæ˜¯å»æŸ¥åº“(tools)è¿˜æ˜¯ç»“æŸ(END)
    workflow.add_conditional_edges(
        "ReAct",
        should_continue,
    )

    # æ·»åŠ æ™®é€šè¾¹ï¼šå·¥å…·æŸ¥å®Œåï¼Œå¿…é¡»æŠŠç»“æœæ‰”å›ç»™ AIï¼Œè®©å®ƒç»§ç»­æ€è€ƒ
    workflow.add_edge("tools", "ReAct")
    # workflow.add_edge("summary", END)  # ç­”æ¡ˆç”Ÿæˆå®Œ -> ç»“æŸ

    app = workflow.compile()
    return app


if __name__ == '__main__':
    nowdate = datetime.datetime.now().strftime('%Y-%m-%d')
    hotel_id = 100785
    user_id = 1384

    app = build_graph()
    # create_visual_graph_pic(app, 'step_by_step_2')

    # question = 'æ ¹æ®ç°åœ¨çš„é¢„è®¢è¿›åº¦ï¼Œå»ºè®®ä¸€ä¸‹æ˜å¤©å¤å¼å¤§åºŠæˆ¿çš„ä»·æ ¼åº”è¯¥å®šå¤šå°‘ï¼Ÿ'
    question = 'å½“å‰çš„æˆ¿æ€æƒ…å†µå¦‚ä½•'
    inputs = {
        "messages": [
            SystemMessage(content=AGENT_SYSTEM_PROMPT.format(hotel_id)),
            HumanMessage(content=AGENT_USER_PROMPT.format(nowdate, hotel_id, user_id, question))
        ]
    }

    logger.info("====== å¼€å§‹è¿è¡Œ Agent ======")

    # stream_mode="values" ä¼šè¿”å›æ¯æ¬¡çŠ¶æ€æ›´æ–°åçš„å®Œæ•´ State
    # ä½†è¿™é‡Œæˆ‘ä»¬ç”¨é»˜è®¤æ¨¡å¼ï¼Œåªè·å–å¢é‡æ›´æ–°ï¼Œè¿™æ ·æ›´æ–¹ä¾¿çœ‹æ¯ä¸€æ­¥åšäº†ä»€ä¹ˆ
    for event in app.stream(inputs, config={"recursion_limit": 50}):
        # 1. æ•è· Agent çš„æ€è€ƒä¸è¡ŒåŠ¨
        if "ReAct" in event:
            # print(event)
            message = event["ReAct"]["messages"][0]
            content = message.content
            tool_calls = message.tool_calls

            # æ‰“å° AI çš„æ€è€ƒæ–‡æœ¬ (å¦‚æœæœ‰)
            if content:
                logger.info(f"[AI å›ç­”]: {content}")

            # æ‰“å° AI å†³å®šè°ƒç”¨çš„å·¥å…·
            if tool_calls:
                for tc in tool_calls:
                    logger.info(f"[è°ƒç”¨å·¥å…·] {tc['name']}: {tc['args']}")

        # 2. æ•è·å·¥å…·çš„è¿”å›ç»“æœ
        elif "tools" in event:
            # print('å·¥å…·è°ƒç”¨')
            # ToolNode è¿”å›çš„æ˜¯ ToolMessage
            message = event["tools"]["messages"][0]
            logger.info(f"[å·¥å…·è¿”å›]: {message.content[:200]}...")  # åªæ‰“å°å‰200å­—é˜²æ­¢åˆ·å±

    logger.info("====== è¿è¡Œç»“æŸ ======")

    # # 1. è¿è¡Œå¹¶è·å–æœ€ç»ˆçŠ¶æ€
    # final_state = app.invoke(inputs)
    #
    # print("\n====== æ¨ç†å…¨è¿‡ç¨‹å¤ç›˜ ======\n")
    #
    # # 2. éå†å†å²æ¶ˆæ¯
    # for msg in final_state["messages"]:
    #
    #     if isinstance(msg, HumanMessage):
    #         print(f"ğŸ‘¤ [ç”¨æˆ·]: {msg.content}")
    #
    #     elif isinstance(msg, AIMessage):
    #         # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
    #         if msg.tool_calls:
    #             print(f"ğŸ¤– [AI æ€è€ƒ]: {msg.content}")  # DeepSeek æœ‰æ—¶ä¼šæŠŠæ€è€ƒå†™åœ¨ content é‡Œ
    #             for tc in msg.tool_calls:
    #                 print(f"ğŸ› ï¸ [AI å†³å®šè°ƒç”¨å·¥å…·]: {tc['name']} -> å‚æ•°: {tc['args']}")
    #         else:
    #             print(f"ğŸ¤– [AI æœ€ç»ˆå›ç­”]: {msg.content}")
    #
    #     elif isinstance(msg, ToolMessage):
    #         print(f"ğŸ“Š [æ•°æ®åº“/å·¥å…· åé¦ˆ]: {msg.content}")
    #
    #     print("-" * 50)
